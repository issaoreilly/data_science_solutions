{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad938426",
   "metadata": {},
   "source": [
    "# Computing Rolling Cosine Similarity Over Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e755567",
   "metadata": {},
   "source": [
    "The objective of this notebook is to provide a fast approach to calculating a rolling window cosine similarity over time series data. The solution is implemented using `Numpy` and `Numba`. The solution can be extended and used for data stored in dataframe. If we check Pandas API, we found an existing solution for the [rolling correlation function](https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.corr.html). However, there is no API covering the rolling cosine similarity. It is not even possible using `.rolling(window_size).apply()` etc. We can definitely find an implemented solution using Numpy, however, I made some modification and used Numba for faster processing/computation. Below is a detailed description to my approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e01ea",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc46bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numba import jit, njit\n",
    "import numba\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ceb3f",
   "metadata": {},
   "source": [
    "# Explanation\n",
    "\n",
    "The main objective of this problem is to calculate the rolling `cosine_similarity` over a given matrix. In other words, I would like to achieve a similar behavior to the pandas native function: `df.rolling(window_size).corr()` which return the corrlation coefficient for each sliding window over a given dataframe. More information about the rolling correlation can be found [here](https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.corr.html). The following figure demonstrate how the sliding window works over `axis=0`.\n",
    "\n",
    "<img src=\"figures/dataframe_sliding_window.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "As a result, each window will be passed to the `corr()` function, and the result of `corr()` is a dataframe of size $(N \\times N)$ where $N$ is the number of columns in the main dataframe. The output of `df.rolling(window_size).corr()` is roughly: $\\left( len(df) - window\\_size + 1, N, N \\right)$.\n",
    "\n",
    "---\n",
    "\n",
    "In the following sections, I will go over the main steps for caclulating the cosine similarity over a 2D array (to be covered in section 1). Under section 2, I will show the main implementation in python I will be using `numba` to achieve faster processing times. Finally, I will apply the `cos_similarity` over a sliding window as shown in the figure above.\n",
    "\n",
    "## Section 1\n",
    "\n",
    "The formula for cosine similarity is:\n",
    "\n",
    "$$\n",
    "cosine \\space similarity(\\vec{a}, \\vec{b}) = \\cos{\\theta} = \\frac{\\vec{a}.\\vec{b}}{\\lvert a \\rvert . \\lvert b \\rvert}\n",
    "$$\n",
    "\n",
    "Therefore, if we have a given matrix $A$ with $m$ number of rows and $N$ number of columns, calculating the cosine similarity between each and every col requires us to go through a nested for loop, consuming every pair of columns, and then apply the cosine formula above. A python code snippet will look like this:\n",
    "\n",
    "```python\n",
    "def calc_cosine_sim(a, b):\n",
    "    dot_product = a*b\n",
    "    a_norm = np.linalg.norm(a)\n",
    "    b_norm = np.linalg.norm(b)\n",
    "    return dot_product / (a_norm * b_norm)\n",
    "\n",
    "A = np.array(some_values)     # A.shape = (m, N)\n",
    "\n",
    "lst = []\n",
    "for i in range(N - 1):\n",
    "    for j in range(i + 1, N):\n",
    "        lst.append(cal_cosine_sim(A[:, i], A[:, j]))\n",
    "```\n",
    "\n",
    "Given that we are calculating the dot product between each and every pair of columns, the same process can be achieved using a matrix multiplication. In other words, if we take the transpose of $A$ and multiply it with itself we should get another matrix who's entries reflect the dot product of $A$'s columns.   \n",
    "\n",
    "Assume we have the following matrix:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}x_{1,1} & x_{1,2} & x_{1,3}\\\\x_{2,1} & x_{2,2} & x_{2,3}\\\\x_{3,1} & x_{3,2} & x_{3,3}\\\\x_{4,1} & x_{4,2} & x_{4,3}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where each row represent one instance, and each col represent a feature, or a vector. Likewise, we will assume \n",
    "\n",
    "$col_1 = \\vec{a}$, $col_2 = \\vec{b}$ and $col_3 = \\vec{c}$. $\\implies A = \\begin{bmatrix} \\vec{a} & \\vec{b} & \\vec{c} \\end{bmatrix}$\n",
    "\n",
    "Multiplying the transpose of A with itself will produce:\n",
    "\n",
    "$$\n",
    "A^{T}.A = \\begin{bmatrix} x_{1,1} & x_{2,1} & x_{3,1} & x_{4,1} \\\\ x_{1,2} & x_{2,2} & x_{3,2} & x_{4,2} \\\\x_{1,3} & x_{2,3} & x_{3,3} & x_{4,3}\\end{bmatrix} . \\begin{bmatrix}x_{1,1} & x_{1,2} & x_{1,3}\\\\x_{2,1} & x_{2,2} & x_{2,3}\\\\x_{3,1} & x_{3,2} & x_{3,3}\\\\x_{4,1} & x_{4,2} & x_{4,3}\\end{bmatrix} = \\begin{bmatrix} \\vec{a}.\\vec{a} & \\vec{a}.\\vec{b} & \\vec{a}.\\vec{c}\\\\\\vec{b}.\\vec{a} & \\vec{b}.\\vec{b} & \\vec{b}.\\vec{c} \\\\ \\vec{c}.\\vec{a} & \\vec{c}.\\vec{b} & \\vec{c}.\\vec{c}\\end{bmatrix} \\space \\space \\space \\space \\space \\space (Equation 1)\n",
    "$$\n",
    "\n",
    "Consequently, using matrix multiplication, I have achieved the same result without using for loops. This process is much faster due to vectorization in numpy.\n",
    "\n",
    "However, the cosine similarity requires us dividing the vector dot product by the norms of both vectors. Therefore, we would love to get this matrix:\n",
    "\n",
    "$$cosine\\_similarity = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\vec{a}.\\vec{a}}{\\lvert a \\rvert . \\lvert a \\rvert} &\n",
    "\\frac{\\vec{a}.\\vec{b}}{\\lvert a \\rvert . \\lvert b \\rvert} &\n",
    "\\frac{\\vec{a}.\\vec{c}}{\\lvert a \\rvert . \\lvert c \\rvert} \\\\\n",
    "\\frac{\\vec{b}.\\vec{a}}{\\lvert b \\rvert . \\lvert a \\rvert} &\n",
    "\\frac{\\vec{b}.\\vec{b}}{\\lvert b \\rvert . \\lvert b \\rvert} &\n",
    "\\frac{\\vec{b}.\\vec{c}}{\\lvert b \\rvert . \\lvert c \\rvert} \\\\\n",
    "\\frac{\\vec{c}.\\vec{a}}{\\lvert c \\rvert . \\lvert a \\rvert} &\n",
    "\\frac{\\vec{c}.\\vec{b}}{\\lvert c \\rvert . \\lvert b \\rvert} &\n",
    "\\frac{\\vec{c}.\\vec{c}}{\\lvert c \\rvert . \\lvert c \\rvert}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "However, this is simply:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "\\vec{a}.\\vec{a} & \\vec{a}.\\vec{b} & \\vec{a}.\\vec{c} \\\\\n",
    "\\vec{b}.\\vec{a} & \\vec{b}.\\vec{b} & \\vec{b}.\\vec{c} \\\\ \n",
    "\\vec{c}.\\vec{a} & \\vec{c}.\\vec{b} & \\vec{c}.\\vec{c}\n",
    "\\end{bmatrix}\n",
    "\\div\n",
    "\\begin{bmatrix}\n",
    "\\lvert a \\rvert . \\lvert a \\rvert &\n",
    "\\lvert a \\rvert . \\lvert b \\rvert &\n",
    "\\lvert a \\rvert . \\lvert c \\rvert \\\\\n",
    "\\lvert b \\rvert . \\lvert a \\rvert &\n",
    "\\lvert b \\rvert . \\lvert b \\rvert &\n",
    "\\lvert b \\rvert . \\lvert c \\rvert \\\\\n",
    "\\lvert c \\rvert . \\lvert a \\rvert &\n",
    "\\lvert c \\rvert . \\lvert b \\rvert &\n",
    "\\lvert c \\rvert . \\lvert c \\rvert\n",
    "\\end{bmatrix} = A^{T}.A \\div norm\\_matrix \\space \\space \\space \\space \\space \"element \\space wise\"\n",
    "$$\n",
    "\n",
    "$$\\implies norm\\_matrix = \n",
    "\\begin{bmatrix}\n",
    "\\lvert a \\rvert . \\lvert a \\rvert &\n",
    "\\lvert a \\rvert . \\lvert b \\rvert &\n",
    "\\lvert a \\rvert . \\lvert c \\rvert \\\\\n",
    "\\lvert b \\rvert . \\lvert a \\rvert &\n",
    "\\lvert b \\rvert . \\lvert b \\rvert &\n",
    "\\lvert b \\rvert . \\lvert c \\rvert \\\\\n",
    "\\lvert c \\rvert . \\lvert a \\rvert &\n",
    "\\lvert c \\rvert . \\lvert b \\rvert &\n",
    "\\lvert c \\rvert . \\lvert c \\rvert\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "However, \n",
    "\n",
    "$$norm\\_matrix = \n",
    "\\begin{bmatrix}\n",
    "\\lvert a \\rvert . \\lvert a \\rvert &\n",
    "\\lvert a \\rvert . \\lvert b \\rvert &\n",
    "\\lvert a \\rvert . \\lvert c \\rvert \\\\\n",
    "\\lvert b \\rvert . \\lvert a \\rvert &\n",
    "\\lvert b \\rvert . \\lvert b \\rvert &\n",
    "\\lvert b \\rvert . \\lvert c \\rvert \\\\\n",
    "\\lvert c \\rvert . \\lvert a \\rvert &\n",
    "\\lvert c \\rvert . \\lvert b \\rvert &\n",
    "\\lvert c \\rvert . \\lvert c \\rvert\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\lvert a \\rvert &\n",
    "\\lvert a \\rvert &\n",
    "\\lvert a \\rvert \\\\\n",
    "\\lvert b \\rvert &\n",
    "\\lvert b \\rvert &\n",
    "\\lvert b \\rvert \\\\\n",
    "\\lvert c \\rvert &\n",
    "\\lvert c \\rvert &\n",
    "\\lvert c \\rvert\n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "\\lvert a \\rvert &\n",
    "\\lvert b \\rvert &\n",
    "\\lvert c \\rvert \\\\\n",
    "\\lvert a \\rvert &\n",
    "\\lvert b \\rvert &\n",
    "\\lvert c \\rvert \\\\\n",
    "\\lvert a \\rvert &\n",
    "\\lvert b \\rvert &\n",
    "\\lvert c \\rvert\n",
    "\\end{bmatrix} = B \\times C\n",
    "$$\n",
    "\n",
    "Therefore, if we simply calculate the norms $\\lvert a \\rvert$, $\\lvert b \\rvert$ and $\\lvert c \\rvert$, and then create the above 2 matrices ($B$ and $C$), that should enable us to calculate the $norm\\_matrix$, which when multiplied by $A^{T}.A$ will return the final result, $cosine\\_similarity$ matrix. In the next section, I will go through the python code to explain how the theory above gets translated into code. \n",
    "\n",
    "One final note: $C = B^{T}$. Therefore, we should only produce $B$, and what will be used to generate $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08417a0",
   "metadata": {},
   "source": [
    "## Section 2\n",
    "\n",
    "Below is the python implementation using numpy. This is a straight forward implementation, without using numba. I have added comments to reflects the steps and matrices generated above, in section 1. Below I have written 2 methods: `calc_rolling_cosine_similarity_v1` and `calc_rolling_cosine_similarity_v2` on purpose so that I use both the `cosine_similarity` implementation from sklearn and my implementation in numpy. The aim is to compare the numbers at the end and make sure the implementation is correct.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f47b75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the implementation of the above logic (section 1) using numpy library\n",
    "def calc_cosine_similarity_on_2darray(arr):\n",
    "    '''\n",
    "    Input is 2D array\n",
    "    Return the cosine similarity matrix over the 2D array. In other words, the result is the cosine similarity between\n",
    "    each and every column of the input 2Darray/matrix.\n",
    "    '''\n",
    "    # Equation 1\n",
    "    arr_x_arr = arr.T @ arr\n",
    "    \n",
    "    # Calculating Matrix B\n",
    "    arr_norm = np.linalg.norm(arr, axis=0)\n",
    "    arr_norm_r = np.expand_dims(arr_norm, axis=0)\n",
    "    arr_norm_r_m = np.tile(arr_norm_r, (arr_norm_r.shape[1], 1))\n",
    "    \n",
    "    # Calculating Matrix C\n",
    "    arr_norm_c_m = arr_norm_r_m.T\n",
    "    # Calculating Matrix norm_matrix\n",
    "    arr_norm_mul = arr_norm_r_m * arr_norm_c_m\n",
    "    \n",
    "    # return matrix: cosine_similarity\n",
    "    return arr_x_arr / arr_norm_mul\n",
    "\n",
    "# This funtion will calculate the rolling cosine similarity using simply the sliding_window_view numpy function and \n",
    "# cosine_similarity from the sklearn library\n",
    "def calc_rolling_cosine_similarity_v1(array, window_size, num_features):\n",
    "    array_2D_windowed = np.squeeze(np.lib.stride_tricks.sliding_window_view(array_2D, \n",
    "                                                                            window_shape=(window_size, num_features)))\n",
    "    # arr is transposed on purpose because the cosine_similarity from sklearn will compute cos_sim between the matrix rows.\n",
    "    # Therefore, the transpose will put the features, aka columns, in the first dimension.\n",
    "    cos_sim = [cosine_similarity(arr.T) for arr in array_2D_windowed]\n",
    "    return cos_sim\n",
    "\n",
    "def calc_rolling_cosine_similarity_v2(array, window_size, num_features):\n",
    "    array_2D_windowed = np.squeeze(np.lib.stride_tricks.sliding_window_view(array_2D, \n",
    "                                                                            window_shape=(window_size, num_features)))\n",
    "    cos_sim = [calc_cosine_similarity_on_2darray(arr) for arr in array_2D_windowed]\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eccc5c",
   "metadata": {},
   "source": [
    "The same implementation modified to use `numba` package in python to speed up our computations. the following numpy functions generated some errors if used with numba:\n",
    "\n",
    "- `np.linalg.norm`\n",
    "- `np.expand_dims`\n",
    "- `np.tile`\n",
    "\n",
    "Finally, I could have implemented manually the numpy function `np.lib.stride_tricks.sliding_window_view`. I am not sure how faster this method could be when used with `numba`. I left this one on purpose due to my time constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2ec512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns the norm of a vector v.\n",
    "@njit\n",
    "def calc_norm(v):\n",
    "    return np.sqrt(np.sum(np.square(v)))\n",
    "\n",
    "# The implementation here is equivalent to the implementation of calc_cosine_similarity_on_2darray above\n",
    "# but modified to utilize the numba python package for faster processing.\n",
    "@njit\n",
    "def calc_cosine_similarity_on_2darray_numba(arr):\n",
    "    '''\n",
    "    Input is 2D array\n",
    "    Return the similarity matrix over the 2D array. In other words, the result is the cosine similarity between\n",
    "    each and every column of the input 2Darray/matrix.\n",
    "    '''\n",
    "    # Equation 1\n",
    "    arr_x_arr = arr.T @ arr\n",
    "\n",
    "    # Calculating Matrix B\n",
    "    arr_norm_r = np.zeros(shape=(1, arr.shape[1]))\n",
    "    for i in range(arr.shape[1]):                    # iterate over each col in arr\n",
    "        arr_norm_r[0, i] = calc_norm(arr[:, i])      # calculate the norm of every col in arr.\n",
    "    arr_norm_r_m = np.ones(shape=(arr.shape[1], arr.shape[1])) * arr_norm_r\n",
    "    \n",
    "    # Calculating Matrix C\n",
    "    arr_norm_c_m = arr_norm_r_m.T\n",
    "    \n",
    "    # Calculating Matrix norm_matrix\n",
    "    arr_norm_mul = arr_norm_r_m * arr_norm_c_m\n",
    "    \n",
    "    # return matrix: cosine_similarity\n",
    "    return arr_x_arr / arr_norm_mul\n",
    "\n",
    "@njit\n",
    "def rolling_cosine_similarity_numba(array_windowed):\n",
    "    cos_sim = [calc_cosine_similarity_on_2darray_numba(arr) for arr in array_windowed]\n",
    "    return cos_sim\n",
    "\n",
    "def calc_rolling_cosine_similarity_numba(arr, window_size, num_features):\n",
    "    array_windowed = np.squeeze(np.lib.stride_tricks.sliding_window_view(arr, window_shape=(window_size, num_features)))\n",
    "    cos_sim = rolling_cosine_similarity_numba(array_windowed)\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31574fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate random signal.\n",
    "def generate_random_walk(_len):\n",
    "    lst = [np.random.randn()]\n",
    "    for i in range(_len - 1): \n",
    "        lst.append(lst[i] + np.random.randn())\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba48ec34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43800, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_len = 24*365*5\n",
    "num_features = 5\n",
    "window_size = 10\n",
    "\n",
    "array_2D = np.array([generate_random_walk(signal_len) for _ in range(num_features)]).T\n",
    "array_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e09983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.93 s ± 376 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "calc_rolling_cosine_similarity_v1(array_2D, window_size, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4528e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05 s ± 50.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "calc_rolling_cosine_similarity_v2(array_2D, window_size, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "375d94a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 ms ± 5.27 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "calc_rolling_cosine_similarity_numba(array_2D, window_size, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9c81dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol1 = np.array(calc_rolling_cosine_similarity_v1(array_2D, window_size, num_features))\n",
    "sol2 = np.array(calc_rolling_cosine_similarity_v2(array_2D, window_size, num_features))\n",
    "sol3 = np.array(calc_rolling_cosine_similarity_numba(array_2D, window_size, num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24e27b79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43791, 5, 5), (43791, 5, 5), (43791, 5, 5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol1.shape, sol2.shape, sol3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48ae1316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(sol1, sol2), np.allclose(sol2, sol3), np.allclose(sol1, sol3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f823b895",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The same solution, when using `numba` is almost $\\frac{9.87}{0.343} \\sim 30$ times faster than the native sklearn implementation, and $\\frac{2.79}{0.343} \\sim 8$ times faster than the same numpy implementation without numba."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
